{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "c182bed3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Current Working Directory: /kaggle/working\n",
                        "'src' directory found.\n",
                        "Contents: ['__init__.py', 'mae_with_adapter.py', 'server.py', 'loss.py', 'client.py']\n"
                    ]
                },
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'imp'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_128/1968319888.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Autoreload (Useful if editing files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
                        "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
                        "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
                        "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
                        "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
                        "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
                        "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/extensions/autoreload.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msource_from_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imp'"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# 0. ENVIRONMENT DIAGNOSTICS & SETUP\n",
                "# =============================================================================\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Ensure the current directory is in SYS.PATH\n",
                "cwd = os.getcwd()\n",
                "if cwd not in sys.path:\n",
                "    sys.path.append(cwd)\n",
                "\n",
                "print(f\"Current Working Directory: {cwd}\")\n",
                "\n",
                "# Verify 'src' folder exists\n",
                "if os.path.isdir('src'):\n",
                "    print(\"'src' directory found.\")\n",
                "    print(f\"Contents: {os.listdir('src')}\")\n",
                "else:\n",
                "    print(\"ERROR: 'src' directory NOT found! Make sure you run this notebook from the project root.\")\n",
                "\n",
                "# Autoreload (Useful if editing files)\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "print(\"Environment setup complete.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "74acd4b9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SUCCESS: Imported src.client\n",
                        "SUCCESS: Imported src.loss\n",
                        "CRITICAL IMPORT ERROR: cannot import name 'GlobalPrototypeBank' from 'src.server' (/kaggle/working/src/server.py)\n",
                        "Please check that 'src' is a valid package (contains __init__.py) and in the path.\n",
                        "src package location: /kaggle/working/src/__init__.py\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# 1. IMPORTS (Explicit & Verbose)\n",
                "# =============================================================================\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from torchvision import transforms, datasets\n",
                "import numpy as np\n",
                "import logging\n",
                "\n",
                "# Local Imports\n",
                "try:\n",
                "    from src.client import ClientManager, FederatedClient\n",
                "    print(\"SUCCESS: Imported src.client\")\n",
                "    \n",
                "    from src.loss import GPADLoss\n",
                "    print(\"SUCCESS: Imported src.loss\")\n",
                "    \n",
                "    from src.server import GlobalPrototypeBank, FederatedModelServer, run_server_round, GlobalModel\n",
                "    print(\"SUCCESS: Imported src.server (GlobalPrototypeBank found)\")\n",
                "    \n",
                "except ImportError as e:\n",
                "    print(f\"CRITICAL IMPORT ERROR: {e}\")\n",
                "    print(\"Please check that 'src' is a valid package (contains __init__.py) and in the path.\")\n",
                "    # Attempt to debug src package location\n",
                "    try:\n",
                "        import src\n",
                "        print(f\"src package location: {src.__file__}\")\n",
                "    except:\n",
                "        pass\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "a3009817",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-02-16 10:09:25,040 [INFO] NotebookTest: Running Test with Config: {'num_clients': 2, 'num_rounds': 3, 'batch_size': 4, 'embedding_dim': 768, 'gpu_count': 2, 'merge_threshold': 0.85, 'ema_alpha': 0.1, 'gpad_base_tau': 0.5, 'gpad_temp_gate': 0.1, 'k_init_prototypes': 5}\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# 2. CONFIGURATION & LOGGING\n",
                "# =============================================================================\n",
                "# Configure Logging\n",
                "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\")\n",
                "logger = logging.getLogger(\"NotebookTest\")\n",
                "\n",
                "CONFIG = {\n",
                "    \"num_clients\": 2,          \n",
                "    \"num_rounds\": 3,           \n",
                "    \"batch_size\": 4,           \n",
                "    \"embedding_dim\": 768,      # ViT Base dim\n",
                "    \"gpu_count\": 2 if torch.cuda.device_count() >= 2 else torch.cuda.device_count(),\n",
                "    \n",
                "    # Loss & Proto Params\n",
                "    \"merge_threshold\": 0.85,\n",
                "    \"ema_alpha\": 0.1,\n",
                "    \"gpad_base_tau\": 0.5,\n",
                "    \"gpad_temp_gate\": 0.1,\n",
                "    \"k_init_prototypes\": 5,\n",
                "}\n",
                "\n",
                "logger.info(f\"Running Test with Config: {CONFIG}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "468ef7ec",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-02-16 10:09:28,427 [INFO] NotebookTest: Attempting to load CIFAR10 for testing...\n",
                        "2026-02-16 10:09:29,378 [INFO] NotebookTest: CIFAR10 loaded successfully.\n",
                        "2026-02-16 10:09:29,381 [INFO] NotebookTest: Data Prepared: 2 Clients with 20 samples each.\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# 3. DATA PREPARATION (Using Torchvision / Mock)\n",
                "# =============================================================================\n",
                "class FakeImageDataset(Dataset):\n",
                "    def __init__(self, size=100, dim=224):\n",
                "        self.data = torch.randn(size, 3, dim, dim)\n",
                "        self.targets = torch.randint(0, 10, (size,))\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.data)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.data[idx], self.targets[idx]\n",
                "\n",
                "# Try real data, fallback to fake\n",
                "try:\n",
                "    logger.info(\"Attempting to load CIFAR10 for testing...\")\n",
                "    transform = transforms.Compose([\n",
                "        transforms.Resize((224, 224)), # ViT expects 224\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize((0.5,), (0.5,))\n",
                "    ])\n",
                "    # subset\n",
                "    # Use download=True if strict internet access. \n",
                "    full_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
                "    # Take just 40 samples per client for speed\n",
                "    indices = np.random.choice(len(full_dataset), 40, replace=False)\n",
                "    subset = torch.utils.data.Subset(full_dataset, indices)\n",
                "    logger.info(\"CIFAR10 loaded successfully.\")\n",
                "    \n",
                "except Exception as e:\n",
                "    logger.warning(f\"Could not load CIFAR10 ({e}). Using Fake Data.\")\n",
                "    subset = FakeImageDataset(size=40)\n",
                "\n",
                "# Split data for 2 clients\n",
                "cutoff = len(subset) // 2\n",
                "ds1, ds2 = torch.utils.data.random_split(subset, [cutoff, len(subset)-cutoff])\n",
                "\n",
                "dl1 = DataLoader(ds1, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
                "dl2 = DataLoader(ds2, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
                "dataloaders = [dl1, dl2]\n",
                "\n",
                "logger.info(f\"Data Prepared: 2 Clients with {len(ds1)} samples each.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "41d62860",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "id": "3a1719cd",
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "GlobalPrototypeBank not found! Did the Imports cell run successfully?",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_128/2262935357.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Ensure GlobalPrototypeBank is defined in current scope (from imports cell)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'GlobalPrototypeBank'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GlobalPrototypeBank not found! Did the Imports cell run successfully?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m proto_bank = GlobalPrototypeBank(\n",
                        "\u001b[0;31mNameError\u001b[0m: GlobalPrototypeBank not found! Did the Imports cell run successfully?"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# 4. COMPONENT INITIALIZATION\n",
                "# =============================================================================\n",
                "\n",
                "# A. Global Prototype Bank\n",
                "# Ensure GlobalPrototypeBank is defined in current scope (from imports cell)\n",
                "if 'GlobalPrototypeBank' not in locals():\n",
                "    raise NameError(\"GlobalPrototypeBank not found! Did the Imports cell run successfully?\")\n",
                "\n",
                "proto_bank = GlobalPrototypeBank(\n",
                "    embedding_dim=CONFIG[\"embedding_dim\"],\n",
                "    merge_threshold=CONFIG[\"merge_threshold\"],\n",
                "    ema_alpha=CONFIG[\"ema_alpha\"],\n",
                "    device=\"cpu\" \n",
                ")\n",
                "\n",
                "# B. Server Aggregator\n",
                "fed_server = FederatedModelServer()\n",
                "\n",
                "# C. Components - Model (Using real ViT if possible, handled by library import check in code)\n",
                "try:\n",
                "    from transformers import ViTMAEForPreTraining\n",
                "    from src.mae_with_adapter import inject_adapters\n",
                "    \n",
                "    logger.info(\"Loading Base ViT-MAE Model...\")\n",
                "    base_model = ViTMAEForPreTraining.from_pretrained(\"facebook/vit-mae-base\")\n",
                "    base_model = inject_adapters(base_model, bottleneck_dim=64)\n",
                "    logger.info(\"Base Model Ready with Adapters.\")\n",
                "    \n",
                "except ImportError:\n",
                "    logger.error(\"Transformers library missing! Can't load ViT-MAE. Using Mock fallback.\")\n",
                "    class MockViTMAE(nn.Module):\n",
                "        def __init__(self, dim=768):\n",
                "            super().__init__()\n",
                "            self.encoder = nn.Linear(dim, dim) \n",
                "            self.config = type('Config', (), {'hidden_size': dim})()\n",
                "        def forward(self, x, output_hidden_states=False, **kwargs):\n",
                "            B = x.size(0)\n",
                "            feat = torch.randn(B, 768).to(x.device)\n",
                "            class Output: pass\n",
                "            out = Output()\n",
                "            out.loss = feat.abs().mean()\n",
                "            out.hidden_states = [feat.unsqueeze(1)]\n",
                "            return out\n",
                "    base_model = MockViTMAE()\n",
                "\n",
                "# D. Client Manager\n",
                "client_manager = ClientManager(\n",
                "    base_model=base_model,\n",
                "    num_clients=CONFIG[\"num_clients\"],\n",
                "    gpu_count=CONFIG[\"gpu_count\"]\n",
                ")\n",
                "\n",
                "# E. Loss Function\n",
                "gpad_loss = GPADLoss(\n",
                "    base_tau=CONFIG[\"gpad_base_tau\"],\n",
                "    temp_gate=CONFIG[\"gpad_temp_gate\"]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "68f13fe0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# 5. PIPELINE EXECUTION\n",
                "# =============================================================================\n",
                "global_protos = None\n",
                "global_weights = None\n",
                "\n",
                "for round_idx in range(1, CONFIG[\"num_rounds\"] + 1):\n",
                "    logger.info(f\"\\n--- Starting Round {round_idx} ---\")\n",
                "    \n",
                "    # 1. Update Clients with Global State (if available)\n",
                "    if global_weights is not None:\n",
                "        logger.info(\"Broadcasting Global Weights to Clients...\")\n",
                "        for client in client_manager.clients:\n",
                "            client.model.load_state_dict(global_weights, strict=False)\n",
                "            \n",
                "    # 2. Train\n",
                "    logger.info(\"Clients Training...\")\n",
                "    losses = client_manager.train_round(\n",
                "        dataloaders,\n",
                "        global_prototypes=global_protos,\n",
                "        gpad_loss_fn=gpad_loss\n",
                "    )\n",
                "    logger.info(f\"Round Losses: {losses}\")\n",
                "    \n",
                "    # 3. Extract Prototypes & Weights\n",
                "    client_payloads = []\n",
                "    logger.info(\"Extracting Client Payloads...\")\n",
                "    for i, client in enumerate(client_manager.clients):\n",
                "        local_protos = client.generate_prototypes(dataloaders[i], K_init=CONFIG[\"k_init_prototypes\"])\n",
                "        weights = {k: v.cpu() for k, v in client.model.state_dict().items()}\n",
                "        \n",
                "        client_payloads.append({\n",
                "            'client_id': f\"client_{i}\",\n",
                "            'protos': local_protos.cpu(),\n",
                "            'weights': weights\n",
                "        })\n",
                "        \n",
                "    # 4. Server Aggregation\n",
                "    logger.info(\"Server Aggregating...\")\n",
                "    server_result = run_server_round(\n",
                "        proto_manager=proto_bank,\n",
                "        model_server=fed_server,\n",
                "        client_payloads=client_payloads\n",
                "    )\n",
                "    \n",
                "    global_protos = server_result['global_prototypes']\n",
                "    global_weights = server_result['global_weights']\n",
                "    \n",
                "    count = global_protos.shape[0] if global_protos is not None else 0\n",
                "    logger.info(f\"Round {round_idx} Complete. Global Prototypes: {count}\")\n",
                "\n",
                "logger.info(\"\\nPipeline Test Finished Successfully!\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
