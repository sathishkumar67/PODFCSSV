{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from torchvision import transforms, datasets\n",
                "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
                "import numpy as np\n",
                "import logging\n",
                "from typing import List, Dict, Any\n",
                "import copy\n",
                "\n",
                "# --- Fix Imports ---\n",
                "import sys\n",
                "import os\n",
                "sys.path.append(os.getcwd())  # Ensure local modules are found\n",
                "\n",
                "from src.server import GlobalPrototypeBank, FederatedModelServer, run_server_round, GlobalModel\n",
                "from src.client import ClientManager, FederatedClient\n",
                "from src.loss import GPADLoss\n",
                "\n",
                "# Configure Logging\n",
                "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\")\n",
                "logger = logging.getLogger(\"NotebookTest\")\n",
                "\n",
                "# =============================================================================\n",
                "# 1. SETUP & CONFIGURATION\n",
                "# =============================================================================\n",
                "CONFIG = {\n",
                "    \"num_clients\": 2,          # As requested\n",
                "    \"num_rounds\": 3,           # Just a few rounds to test pipeline\n",
                "    \"batch_size\": 4,           # Small batch for quick test (or mock)\n",
                "    \"embedding_dim\": 768,      # ViT Base dim\n",
                "    \"gpu_count\": 2 if torch.cuda.device_count() >= 2 else torch.cuda.device_count(),\n",
                "    \n",
                "    # Loss & Proto Params\n",
                "    \"merge_threshold\": 0.85,\n",
                "    \"ema_alpha\": 0.1,\n",
                "    \"gpad_base_tau\": 0.5,\n",
                "    \"gpad_temp_gate\": 0.1,\n",
                "    \"k_init_prototypes\": 5,\n",
                "}\n",
                "\n",
                "logger.info(f\"Running Test with Config: {CONFIG}\")\n",
                "\n",
                "# =============================================================================\n",
                "# 2. DATA PREPARATION (Using Torchvision / Mock)\n",
                "# =============================================================================\n",
                "# We'll use a tiny subset of CIFAR10 to ensure it runs quickly even if downloading is slow\n",
                "# Or fake data if download fails to be robust.\n",
                "\n",
                "class FakeImageDataset(Dataset):\n",
                "    def __init__(self, size=100, dim=224):\n",
                "        self.data = torch.randn(size, 3, dim, dim)\n",
                "        self.targets = torch.randint(0, 10, (size,))\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.data)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.data[idx], self.targets[idx]\n",
                "\n",
                "# Try real data, fallback to fake\n",
                "try:\n",
                "    logger.info(\"Attempting to load CIFAR10 for testing...\")\n",
                "    transform = transforms.Compose([\n",
                "        transforms.Resize((224, 224)), # ViT expects 224\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize((0.5,), (0.5,))\n",
                "    ])\n",
                "    # subset\n",
                "    # Use download=True if strict internet access. \n",
                "    full_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
                "    # Take just 40 samples per client for speed\n",
                "    indices = np.random.choice(len(full_dataset), 40, replace=False)\n",
                "    subset = torch.utils.data.Subset(full_dataset, indices)\n",
                "    logger.info(\"CIFAR10 loaded successfully.\")\n",
                "    \n",
                "except Exception as e:\n",
                "    logger.warning(f\"Could not load CIFAR10 ({e}). Using Fake Data.\")\n",
                "    subset = FakeImageDataset(size=40)\n",
                "\n",
                "# Split data for 2 clients\n",
                "cutoff = len(subset) // 2\n",
                "ds1, ds2 = torch.utils.data.random_split(subset, [cutoff, len(subset)-cutoff])\n",
                "\n",
                "dl1 = DataLoader(ds1, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
                "dl2 = DataLoader(ds2, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
                "dataloaders = [dl1, dl2]\n",
                "\n",
                "logger.info(f\"Data Prepared: 2 Clients with {len(ds1)} samples each.\")\n",
                "\n",
                "# =============================================================================\n",
                "# 3. INITIALIZE COMPONENTS\n",
                "# =============================================================================\n",
                "\n",
                "# A. Global Prototype Bank\n",
                "proto_bank = GlobalPrototypeBank(\n",
                "    embedding_dim=CONFIG[\"embedding_dim\"],\n",
                "    merge_threshold=CONFIG[\"merge_threshold\"],\n",
                "    ema_alpha=CONFIG[\"ema_alpha\"],\n",
                "    device=\"cpu\" \n",
                ")\n",
                "\n",
                "# B. Server Aggregator\n",
                "fed_server = FederatedModelServer()\n",
                "\n",
                "# C. Components - Model (Using real ViT if possible, handled by library import check in code)\n",
                "# Since we are in notebook with GPU, let's try strict real model\n",
                "try:\n",
                "    from transformers import ViTMAEForPreTraining\n",
                "    # We need to make sure we inject adapters. \n",
                "    # The `src.mae_with_adapter` handles this logic.\n",
                "    from src.mae_with_adapter import inject_adapters\n",
                "    \n",
                "    logger.info(\"Loading Base ViT-MAE Model...\")\n",
                "    base_model = ViTMAEForPreTraining.from_pretrained(\"facebook/vit-mae-base\")\n",
                "    base_model = inject_adapters(base_model, bottleneck_dim=64)\n",
                "    logger.info(\"Base Model Ready with Adapters.\")\n",
                "    \n",
                "except ImportError:\n",
                "    logger.error(\"Transformers library missing! Can't load ViT-MAE. Using Mock fallback.\")\n",
                "    # Mock Model definition similar to main.py\n",
                "    class MockViTMAE(nn.Module):\n",
                "        def __init__(self, dim=768):\n",
                "            super().__init__()\n",
                "            self.encoder = nn.Linear(dim, dim) # Dummy\n",
                "            self.config = type('Config', (), {'hidden_size': dim})()\n",
                "        def forward(self, x, output_hidden_states=False, **kwargs):\n",
                "            # x: (B, 3, 224, 224) -> Flatten to (B, D) effectively\n",
                "            B = x.size(0)\n",
                "            feat = torch.randn(B, 768).to(x.device)\n",
                "            class Output: pass\n",
                "            out = Output()\n",
                "            out.loss = feat.abs().mean()\n",
                "            out.hidden_states = [feat.unsqueeze(1)]\n",
                "            return out\n",
                "    base_model = MockViTMAE()\n",
                "\n",
                "# D. Client Manager\n",
                "client_manager = ClientManager(\n",
                "    base_model=base_model,\n",
                "    num_clients=CONFIG[\"num_clients\"],\n",
                "    gpu_count=CONFIG[\"gpu_count\"]\n",
                ")\n",
                "\n",
                "# E. Loss Function\n",
                "gpad_loss = GPADLoss(\n",
                "    base_tau=CONFIG[\"gpad_base_tau\"],\n",
                "    temp_gate=CONFIG[\"gpad_temp_gate\"]\n",
                ")\n",
                "\n",
                "# =============================================================================\n",
                "# 4. RUN PIPELINE (3 Rounds)\n",
                "# =============================================================================\n",
                "global_protos = None\n",
                "global_weights = None\n",
                "\n",
                "for round_idx in range(1, CONFIG[\"num_rounds\"] + 1):\n",
                "    logger.info(f\"\\n--- Starting Round {round_idx} ---\")\n",
                "    \n",
                "    # 1. Update Clients with Global State (if available)\n",
                "    if global_weights is not None:\n",
                "        logger.info(\"Broadcasting Global Weights to Clients...\")\n",
                "        # In simulation: Manually load into each client\n",
                "        for client in client_manager.clients:\n",
                "            client.model.load_state_dict(global_weights, strict=False)\n",
                "            \n",
                "    # 2. Train\n",
                "    logger.info(\"Clients Training...\")\n",
                "    losses = client_manager.train_round(\n",
                "        dataloaders,\n",
                "        global_prototypes=global_protos,\n",
                "        gpad_loss_fn=gpad_loss\n",
                "    )\n",
                "    logger.info(f\"Round Losses: {losses}\")\n",
                "    \n",
                "    # 3. Extract Prototypes & Weights\n",
                "    client_payloads = []\n",
                "    logger.info(\"Extracting Client Payloads...\")\n",
                "    for i, client in enumerate(client_manager.clients):\n",
                "        # Protos\n",
                "        local_protos = client.generate_prototypes(dataloaders[i], K_init=CONFIG[\"k_init_prototypes\"])\n",
                "        \n",
                "        # Weights (CPU for aggregation)\n",
                "        weights = {k: v.cpu() for k, v in client.model.state_dict().items()}\n",
                "        \n",
                "        client_payloads.append({\n",
                "            'client_id': f\"client_{i}\",\n",
                "            'protos': local_protos.cpu(),\n",
                "            'weights': weights\n",
                "        })\n",
                "        \n",
                "    # 4. Server Aggregation\n",
                "    logger.info(\"Server Aggregating...\")\n",
                "    server_result = run_server_round(\n",
                "        proto_manager=proto_bank,\n",
                "        model_server=fed_server,\n",
                "        client_payloads=client_payloads\n",
                "    )\n",
                "    \n",
                "    global_protos = server_result['global_prototypes']\n",
                "    global_weights = server_result['global_weights']\n",
                "    \n",
                "    if global_protos is not None:\n",
                "        logger.info(f\"Round {round_idx} Complete. Global Prototypes: {global_protos.shape[0]}\")\n",
                "    else:\n",
                "        logger.info(f\"Round {round_idx} Complete. Global Prototypes: 0\")\n",
                "\n",
                "logger.info(\"\\nPipeline Test Finished Successfully!\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}