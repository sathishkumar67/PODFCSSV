{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# IMPORT MODULES\n",
                "# =============================================================================\n",
                "import os\n",
                "import sys\n",
                "import logging\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from torchvision import transforms, datasets\n",
                "\n",
                "# Ensure local modules are found\n",
                "if os.getcwd() not in sys.path:\n",
                "    sys.path.append(os.getcwd())\n",
                "\n",
                "# Explicit Imports from Project\n",
                "from src.client import ClientManager, FederatedClient\n",
                "from src.loss import GPADLoss\n",
                "from src.server import GlobalPrototypeBank, FederatedModelServer, run_server_round, GlobalModel\n",
                "\n",
                "# Configure Logging\n",
                "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\")\n",
                "logger = logging.getLogger(\"NotebookRequest\")\n",
                "\n",
                "print(\"Modules imported successfully.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# CONFIGURATION\n",
                "# =============================================================================\n",
                "CONFIG = {\n",
                "    \"num_clients\": 2,          \n",
                "    \"num_rounds\": 3,           \n",
                "    \"batch_size\": 8,           \n",
                "    \"embedding_dim\": 768,      # ViT Base dim\n",
                "    \"gpu_count\": 2 if torch.cuda.device_count() >= 2 else torch.cuda.device_count(),\n",
                "    \n",
                "    # Loss & Proto Params\n",
                "    \"merge_threshold\": 0.85,\n",
                "    \"ema_alpha\": 0.1,\n",
                "    \"gpad_base_tau\": 0.5,\n",
                "    \"gpad_temp_gate\": 0.1,\n",
                "    \"k_init_prototypes\": 5,\n",
                "}\n",
                "\n",
                "logger.info(f\"Starting Pipeline Test with Config: {CONFIG}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# DATA PREPARATION (CIFAR10)\n",
                "# =============================================================================\n",
                "\n",
                "# Define Transforms (Resize to 224 for ViT)\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)), \n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
                "])\n",
                "\n",
                "# Load Dataset\n",
                "try:\n",
                "    logger.info(\"Loading CIFAR10...\")\n",
                "    full_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
                "    \n",
                "    # Use a small subset for speed\n",
                "    subset_size = 100\n",
                "    indices = np.random.choice(len(full_dataset), subset_size, replace=False)\n",
                "    subset = torch.utils.data.Subset(full_dataset, indices)\n",
                "    \n",
                "    # Split for 2 clients\n",
                "    lengths = [subset_size // 2, subset_size - (subset_size // 2)]\n",
                "    ds1, ds2 = torch.utils.data.random_split(subset, lengths)\n",
                "    \n",
                "    dl1 = DataLoader(ds1, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
                "    dl2 = DataLoader(ds2, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
                "    dataloaders = [dl1, dl2]\n",
                "    \n",
                "    logger.info(f\"Data Ready: 2 Clients with {len(ds1)} samples each.\")\n",
                "    \n",
                "except Exception as e:\n",
                "    logger.error(f\"Data loading failed: {e}\")\n",
                "    raise\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# INITIALIZE COMPONENTS\n",
                "# =============================================================================\n",
                "\n",
                "# 1. Global Prototype Bank\n",
                "proto_bank = GlobalPrototypeBank(\n",
                "    embedding_dim=CONFIG[\"embedding_dim\"],\n",
                "    merge_threshold=CONFIG[\"merge_threshold\"],\n",
                "    ema_alpha=CONFIG[\"ema_alpha\"],\n",
                "    device=\"cpu\" \n",
                ")\n",
                "\n",
                "# 2. Global Model Server (Aggregation)\n",
                "fed_server = FederatedModelServer()\n",
                "\n",
                "# 3. Base Model (ViT-MAE with Adapters)\n",
                "try:\n",
                "    from transformers import ViTMAEForPreTraining\n",
                "    from src.mae_with_adapter import inject_adapters\n",
                "    \n",
                "    logger.info(\"Initializing ViT-MAE Backbone...\")\n",
                "    base_model = ViTMAEForPreTraining.from_pretrained(\"facebook/vit-mae-base\")\n",
                "    base_model = inject_adapters(base_model, bottleneck_dim=64)\n",
                "    logger.info(\"Adapters Injected Successfully.\")\n",
                "    \n",
                "except ImportError:\n",
                "    logger.warning(\"Transformers not found. Logic will fail unless mocked.\")\n",
                "    raise\n",
                "\n",
                "# 4. Client Manager\n",
                "client_manager = ClientManager(\n",
                "    base_model=base_model,\n",
                "    num_clients=CONFIG[\"num_clients\"],\n",
                "    gpu_count=CONFIG[\"gpu_count\"]\n",
                ")\n",
                "\n",
                "# 5. GPAD Loss\n",
                "gpad_loss = GPADLoss(\n",
                "    base_tau=CONFIG[\"gpad_base_tau\"],\n",
                "    temp_gate=CONFIG[\"gpad_temp_gate\"]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# EXECUTE PIPELINE\n",
                "# =============================================================================\n",
                "global_protos = None\n",
                "global_weights = None\n",
                "\n",
                "for round_idx in range(1, CONFIG[\"num_rounds\"] + 1):\n",
                "    logger.info(f\"\\n--- Starting Round {round_idx} / {CONFIG['num_rounds']} ---\")\n",
                "    \n",
                "    # A. Broadcast Global Weights (if exists)\n",
                "    if global_weights is not None:\n",
                "        logger.info(\"> Broadcasting Global Weights...\")\n",
                "        for client in client_manager.clients:\n",
                "            client.model.load_state_dict(global_weights, strict=False)\n",
                "            \n",
                "    # B. Client Training Step\n",
                "    logger.info(\"> Clients Training...\")\n",
                "    losses = client_manager.train_round(\n",
                "        dataloaders,\n",
                "        global_prototypes=global_protos,\n",
                "        gpad_loss_fn=gpad_loss\n",
                "    )\n",
                "    logger.info(f\"  Mean Batch Loss per Client: {losses}\")\n",
                "    \n",
                "    # C. Extract Payloads (Protos + Weights)\n",
                "    client_payloads = []\n",
                "    logger.info(\"> Extracting Prototypes and Weights...\")\n",
                "    for i, client in enumerate(client_manager.clients):\n",
                "        # Generate Local Prototypes (K-Means)\n",
                "        local_protos = client.generate_prototypes(dataloaders[i], K_init=CONFIG[\"k_init_prototypes\"])\n",
                "        \n",
                "        # Get Weights (CPU)\n",
                "        weights = {k: v.cpu() for k, v in client.model.state_dict().items()}\n",
                "        \n",
                "        client_payloads.append({\n",
                "            'client_id': f\"client_{i}\",\n",
                "            'protos': local_protos.cpu(),\n",
                "            'weights': weights\n",
                "        })\n",
                "        \n",
                "    # D. Server Aggregation\n",
                "    logger.info(\"> Server Aggregating...\")\n",
                "    server_result = run_server_round(\n",
                "        proto_manager=proto_bank,\n",
                "        model_server=fed_server,\n",
                "        client_payloads=client_payloads\n",
                "    )\n",
                "    \n",
                "    global_protos = server_result['global_prototypes']\n",
                "    global_weights = server_result['global_weights']\n",
                "    \n",
                "    proto_count = global_protos.shape[0] if global_protos is not None else 0\n",
                "    logger.info(f\"  Round Complete. Global Prototype Bank Size: {proto_count}\")\n",
                "\n",
                "logger.info(\"\\n*** Pipeline Execution Finished Successfully ***\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}